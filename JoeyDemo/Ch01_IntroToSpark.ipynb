{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/roitraining/SparkforDataEngineers/blob/Development/Ch01_IntroToSpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stLlpheLWf_j"
   },
   "source": [
    "### Create the Spark context to start a session and connect to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oC4ujoSFWf_m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing pyspark\n",
      "pyspark initialized\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "rootpath = '/home/student/ROI/Spark/'\n",
    "datapath = f'{rootpath}datasets/'\n",
    "sys.path.append(rootpath)\n",
    "from pyspark_helpers import *\n",
    "sc, spark, conf = initspark()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uH-N0vuoWf_v"
   },
   "source": [
    "### Read a text file from the local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6iEi36CWf_w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124797\n",
      "['King Joey is really Shakespeare', '\\ufeffThe Project Gutenberg EBook of The Complete Works of William Shakespeare, by ', 'William Shakespeare', '', 'This eBook is for the use of anyone anywhere at no cost and with', 'almost no restrictions whatsoever.  You may copy it, give it away or', 're-use it under the terms of the Project Gutenberg License included', 'with this eBook or online at www.gutenberg.org', '', '** This is a COPYRIGHTED Project Gutenberg eBook, Details Below **']\n"
     ]
    }
   ],
   "source": [
    "shake = sc.textFile(f'{datapath}/text/shakespeare.txt')\n",
    "print(shake.count())\n",
    "print(shake.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bt-1Pg9DWf_1"
   },
   "source": [
    "### Use the map method to apply a function call on each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3wwsvU6Wf_2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KING JOEY IS REALLY SHAKESPEARE',\n",
       " '\\ufeffTHE PROJECT GUTENBERG EBOOK OF THE COMPLETE WORKS OF WILLIAM SHAKESPEARE, BY ',\n",
       " 'WILLIAM SHAKESPEARE',\n",
       " '',\n",
       " 'THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE AT NO COST AND WITH',\n",
       " 'ALMOST NO RESTRICTIONS WHATSOEVER.  YOU MAY COPY IT, GIVE IT AWAY OR',\n",
       " 'RE-USE IT UNDER THE TERMS OF THE PROJECT GUTENBERG LICENSE INCLUDED',\n",
       " 'WITH THIS EBOOK OR ONLINE AT WWW.GUTENBERG.ORG',\n",
       " '',\n",
       " '** THIS IS A COPYRIGHTED PROJECT GUTENBERG EBOOK, DETAILS BELOW **']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shake2 = shake.map(str.upper)\n",
    "shake2.take(10)\n",
    "\n",
    "sc.textFile(f'{datapath}/text/shakespeare.txt').map(str.upper).filter(lambda x : 'KING' in x).take(10)\n",
    "\n",
    "# x would be a python list because of the take action\n",
    "x = sc.textFile(f'{datapath}/text/shakespeare.txt') \\\n",
    "  .map(str.upper) \\\n",
    "  .filter(lambda x : 'KING' in x) \\\n",
    "  .take(10)\n",
    "\n",
    "# x would be a RDD list because it's just a chain of transformations\n",
    "x = sc.textFile(f'{datapath}/text/shakespeare.txt') \\\n",
    "  .map(str.upper) \\\n",
    "  .filter(lambda x : 'KING' in x) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "['5,Grains/Cereals,Breads crackers pasta and cereal', '1,Beverages,Soft drinks coffees teas beers and ales', '2,Condiments,Sweet and savory sauces relishes spreads and seasonings', '3,Confections,Desserts candies and sweet breads', '4,Dairy Products,Cheeses', '6,Meat/Poultry,Prepared meats', '7,Produce,Dried fruit and bean curd', '8,Seafood,Seaweed and fish']\n"
     ]
    }
   ],
   "source": [
    "categories = sc.textFile('hdfs://localhost:9000/categories')\n",
    "print(categories.count())\n",
    "print(categories.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qx0qMtPyWf_9"
   },
   "source": [
    "### Using the split method you get a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Szr74Z3AWf__"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Joeyz'], ['The', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Complete', 'Works', 'of', 'William', 'Shakespeare,', 'by', ''], ['William', 'Shakespeare'], [''], ['This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with'], ['almost', 'no', 'restrictions', 'whatsoever.', '', 'You', 'may', 'copy', 'it,', 'give', 'it', 'away', 'or'], ['re-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included'], ['with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org'], [''], ['**', 'This', 'is', 'a', 'COPYRIGHTED', 'Project', 'Gutenberg', 'eBook,', 'Details', 'Below', '**']]\n",
      "124797\n"
     ]
    }
   ],
   "source": [
    "shake3 = shake.map(lambda x : x.split(' '))\n",
    "print(shake3.take(10))\n",
    "print(shake3.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-L0L9BiWgAF"
   },
   "source": [
    "### The flatMap method flattens the inner list to return one big list of strings instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP2oWr9CWgAI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joeyz', 'The', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Complete', 'Works', 'of', 'William', 'Shakespeare,', 'by', '', 'William', 'Shakespeare', '', 'This', 'eBook', 'is']\n",
      "1410760\n"
     ]
    }
   ],
   "source": [
    "shake4 = shake.flatMap(lambda x : x.split(' '))\n",
    "print(shake4.take(20))\n",
    "print(shake4.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdStyssVWgAU"
   },
   "source": [
    "### Parallelize will load manually created data into the spark cluster into an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XN8v44eNWgAW"
   },
   "outputs": [],
   "source": [
    "r = sc.parallelize(range(1,11))\n",
    "print(r.collect())\n",
    "print(r.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQVoJi3CWgAo"
   },
   "source": [
    "### Load a folder stored on HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tL89iGyOWgAq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,Grains/Cereals,Breads crackers pasta and cereal',\n",
       " '1,Beverages,Soft drinks coffees teas beers and ales',\n",
       " '2,Condiments,Sweet and savory sauces relishes spreads and seasonings',\n",
       " '3,Confections,Desserts candies and sweet breads',\n",
       " '4,Dairy Products,Cheeses',\n",
       " '6,Meat/Poultry,Prepared meats',\n",
       " '7,Produce,Dried fruit and bean curd',\n",
       " '8,Seafood,Seaweed and fish']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = sc.textFile('hdfs://localhost:9000/categories')\n",
    "cat.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FlQ_B5enWgAz"
   },
   "source": [
    "### Other useful actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCqmMuFLWgA1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['1,Beverages,Soft drinks coffees teas beers and ales', '2,Condiments,Sweet and savory sauces relishes spreads and seasonings', '3,Confections,Desserts candies and sweet breads', '4,Dairy Products,Cheeses', '5,Grains/Cereals,Breads crackers pasta and cereal']\n",
      "['1,Beverages,Soft drinks coffees teas beers and ales', '2,Condiments,Sweet and savory sauces relishes spreads and seasonings', '3,Confections,Desserts candies and sweet breads', '4,Dairy Products,Cheeses', '5,Grains/Cereals,Breads crackers pasta and cereal']\n",
      "['8,Seafood,Seaweed and fish', '7,Produce,Dried fruit and bean curd', '6,Meat/Poultry,Prepared meats', '5,Grains/Cereals,Breads crackers pasta and cereal', '4,Dairy Products,Cheeses']\n",
      "['7,Produce,Dried fruit and bean curd', '5,Grains/Cereals,Breads crackers pasta and cereal', '2,Condiments,Sweet and savory sauces relishes spreads and seasonings', '1,Beverages,Soft drinks coffees teas beers and ales', '4,Dairy Products,Cheeses']\n"
     ]
    }
   ],
   "source": [
    "print('1', cat.sortBy(lambda x : x[2:]).take(5))\n",
    "print(cat.takeOrdered(5))\n",
    "print(cat.top(5))\n",
    "print(cat.takeSample(False,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(cat.map(str.upper).collect())\n",
    "\n",
    "def email(x):\n",
    "    print (f'I am sending an email to {x}')\n",
    "\n",
    "    \n",
    "# for x in cat.collect():\n",
    "#     email(x)\n",
    "\n",
    "# for x in cat.toLocalIterator():\n",
    "#     email(x)\n",
    "\n",
    "cat.foreach(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqD-2-05WgBC"
   },
   "source": [
    "### Save the results in an RDD to disk. Note how it makes a folder and fills it with as many files as there are nodes solving the problem. Also, you must make sure that the folder does not exist or it throws an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "au3L8fPDWgBE"
   },
   "outputs": [],
   "source": [
    "! rm -r /home/student/file1.txt\n",
    "cat.saveAsTextFile('/home/student/file1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK88KrBTWgBN"
   },
   "outputs": [],
   "source": [
    "print(cat.map(str.upper).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vn43ZGHWgBT"
   },
   "source": [
    "### Parse the string into a tuple to resemble a record structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJ2bIehvWgBU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'Grains/Cereals', 'Breads crackers pasta and cereal'),\n",
       " (4, 'Dairy Products', 'Cheeses'),\n",
       " (3, 'Confections', 'Desserts candies and sweet breads'),\n",
       " (7, 'Produce', 'Dried fruit and bean curd'),\n",
       " (6, 'Meat/Poultry', 'Prepared meats'),\n",
       " (8, 'Seafood', 'Seaweed and fish'),\n",
       " (1, 'Beverages', 'Soft drinks coffees teas beers and ales'),\n",
       " (2, 'Condiments', 'Sweet and savory sauces relishes spreads and seasonings')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1 = cat.map(lambda x : tuple(x.split(',')))\n",
    "cat1 = cat1.map(lambda x : (int(x[0]), x[1], x[2]))\n",
    "cat1.take(10)\n",
    "\n",
    "# cat1 = cat.map(lambda x : tuple(x.split(','))).map(lambda x : (int(x[0]), x[1], x[2]))\n",
    "# cat1 = cat.map(lambda x : tuple(x.split(','))) \\\n",
    "#           .map(lambda x : (int(x[0]), x[1], x[2]))\n",
    "\n",
    "cat1.sortBy(lambda x : x[2]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ko12EKvYWgBX"
   },
   "source": [
    "### ***LAB:*** Put the regions folder found in /home/student/ROI/Spark/datasets/northwind/CSV/regions into HDFS. Read it into an RDD and convert it into a tuple shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZWX8p7nWgBY"
   },
   "outputs": [],
   "source": [
    "#! hadoop fs -rm -r /regions\n",
    "#! hadoop fs -put /home/student/ROI/Spark/datasets/northwind/CSV/regions /regions\n",
    "#regions = sc.textFile('hdfs://localhost:9000/regions')\n",
    "#regions = regions.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1]))\n",
    "\n",
    "regions = sc.textFile('hdfs://localhost:9000/regions').map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1]))\n",
    "\n",
    "print (regions.collect())\n",
    "#regions.saveAsTextFile('hdfs://localhost:9000/regions2')\n",
    "print(regions.sortBy(lambda x : - x[0]).collect())\n",
    "print(regions.sortBy(lambda x : x[1]).collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat1.collect())\n",
    "cat2 = cat1.map(lambda x : (x[0], (x[1], x[2])))\n",
    "print(cat2.collect())\n",
    "print(cat2.sortByKey().collect())\n",
    "\n",
    "cat3 = cat1.map(lambda x : (x[0], 1))\n",
    "cat3.collect()\n",
    "print('*', cat3.reduceByKey(lambda x, y : x + y).collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1451bwFaWgBn"
   },
   "source": [
    "### The filter method takes a lambda that returns a True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQzyEYCYWgBo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'Grains/Cereals', 'Breads crackers pasta and cereal'),\n",
       " (1, 'Beverages', 'Soft drinks coffees teas beers and ales'),\n",
       " (2, 'Condiments', 'Sweet and savory sauces relishes spreads and seasonings'),\n",
       " (3, 'Confections', 'Desserts candies and sweet breads'),\n",
       " (4, 'Dairy Products', 'Cheeses')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1.filter(lambda x : x[0] <= 5).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22q9mGVrWgBu"
   },
   "source": [
    "### The filter expressions can be more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIEc83jgWgBw"
   },
   "outputs": [],
   "source": [
    "cat1.filter(lambda x : x[0] % 2 == 0 and 'e' in x[1]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-mS0TT9WgB6"
   },
   "source": [
    "### The sortBy method returns an expression that is used to sort the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQwZ4Z_vWgB7"
   },
   "outputs": [],
   "source": [
    "cat1.sortBy(lambda x : x[2]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4gTRsTrWgCD"
   },
   "source": [
    "### sortBy has an option ascending parameter to sort in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRq5r1UAWgCF"
   },
   "outputs": [],
   "source": [
    "cat1.sortBy(lambda x : x[0], ascending = False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = sc.parallelize([{'ID':1, 'FirstName':'Joey'}, {'ID':2, 'FirstName':'Mary'}])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "IntroToSpark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
