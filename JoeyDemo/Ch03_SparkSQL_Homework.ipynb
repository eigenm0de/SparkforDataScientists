{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/roitraining/SparkforDataEngineers/blob/Development/Ch03_SparkSQL_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TRqRWvfo2Ca"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "rootpath = '/home/student/ROI/Spark/'\n",
    "datapath = f'{rootpath}datasets/'\n",
    "sys.path.append(rootpath)\n",
    "from pyspark_helpers import *\n",
    "sc, spark, conf = initspark()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86l8gEeNo2Ck"
   },
   "source": [
    "### Homework ##\n",
    "\n",
    "### First Challenge\n",
    "Create a Python function to determine if a number is odd or even and use that to select only the even numbered shippers from the TSV folder of northwind. Note the TSV file does not have headers so you will need to do something to make the DataFrame have a meaningful structure. I would suggest using SparkSql as much as possible to rename and cast the columns which are ShipperID, CompanyName, and Phone.\n",
    "\n",
    "### Second Challenge\n",
    "Take the Order_LineItems.json folder, read it into a DataFrame, and flatten it and then calculate the average price paid for a product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89KqfEFQo2Cl"
   },
   "outputs": [],
   "source": [
    "o = spark.read.csv(f'{datapath}/northwind/CSVHeaders/orders', header = True, inferSchema = True)\n",
    "od = spark.read.csv(f'{datapath}/northwind/CSVHeaders/orderdetails', header = True, inferSchema = True)\n",
    "\n",
    "o.createOrReplaceTempView('Orders')\n",
    "od.createOrReplaceTempView('OrderDetails')\n",
    "sql = \"\"\"\n",
    "select o.OrderID, o.CustomerID, o.OrderDate\n",
    "           , COLLECT_SET(NAMED_STRUCT(\"ProductID\", od.ProductID, \n",
    "                                      \"UnitPrice\", od.UnitPrice,\n",
    "                                      \"Quantity\", od.Quantity,\n",
    "                                      \"Discount\", od.discount)) as LineItems\n",
    "from Orders as o join OrderDetails as od on o.OrderID = od.OrderID\n",
    "GROUP BY o.OrderID, o.CustomerID, o.OrderDate\n",
    "ORDER BY o.OrderID\n",
    "\"\"\"\n",
    "od2 = spark.sql(sql)\n",
    "od2.write.mode('overwrite').json(f'{rootpath}Orders_LineItems.json')\n",
    "print('Done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAb6t5Xao2Cq"
   },
   "outputs": [],
   "source": [
    "shippers = spark.read.csv(f'{datapath}/northwind/TSV/shippers', header=False, sep = '\\t')\n",
    "#shippers.show()\n",
    "print(shippers)\n",
    "shippers.createOrReplaceTempView('shippers')\n",
    "print(shippers.collect())\n",
    "shippers = spark.sql('select cast(_c0 as int) as ShipperID, _c1 as ShipperName, _c2 as Phone from shippers')\n",
    "shippers.createOrReplaceTempView('shippers')\n",
    "print(shippers)\n",
    "\n",
    "def isEven(x):\n",
    "    return x % 2 == 0\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark.udf.register('isEven', isEven, BooleanType())\n",
    "\n",
    "spark.sql('select * FROM Shippers WHERE isEven(ShipperID)').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrZXzt4wo2Cu"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "o = spark.read.json(f'{rootpath}/Orders_LineItems.json')\n",
    "display(o)\n",
    "o.createOrReplaceTempView('Orders')\n",
    "sql = '''\n",
    "select OrderId, CustomerID, OrderDate, l.ProductID, l.UnitPrice, l.Quantity, l.Discount\n",
    "FROM Orders LATERAL VIEW EXPLODE(LineItems) EXPLODED_TABLE AS l\n",
    "'''\n",
    "o2 = spark.sql(sql)\n",
    "#display(o2)\n",
    "\n",
    "o2.groupby('ProductID').agg(avg('UnitPrice')).show()\n",
    "\n",
    "# o2.createOrReplaceTempView('FlatOrders')\n",
    "# spark.sql('select avg(UnitPrice) from FlatOrders').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AC_U43JHo2Cy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Ch03_SparkSQL_Homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
