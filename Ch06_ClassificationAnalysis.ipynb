{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch06_ClassificationAnalysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roitraining/SparkforDataScientists/blob/Development/Ch06_ClassificationAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVESJgGmrOnE",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "rootpath = '/home/student/ROI/Spark/'\n",
        "datapath = f'{rootpath}datasets/'\n",
        "sys.path.append(rootpath)\n",
        "import pyspark_helpers as pyh\n",
        "from pyspark_helpers import *\n",
        "sc, spark, conf = initspark()\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as mp\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from pyspark_helpers import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quy3emkfO61e",
        "colab_type": "text"
      },
      "source": [
        "### Let's read in a bank data set to try to predict if a potential borrower will default on their loan before lending to them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xOtG6pXJrOnN",
        "colab": {}
      },
      "source": [
        "filename = 'bank.csv'\n",
        "df = spark.read.csv(f'{datapath}/finance/{filename}', header = True, inferSchema = True)\n",
        "display(df)\n",
        "\n",
        "# Save a pointer to the raw data\n",
        "dfRawFile = df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GANPzRyhO61o",
        "colab_type": "text"
      },
      "source": [
        "### Clean up the dataset by identifying the numeric and categorical features and target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-FZqXtsrOnR",
        "colab": {}
      },
      "source": [
        "# Let's just keep a few fields to start with for simplicity\n",
        "numeric_features = ['age','balance', 'duration', 'pdays']\n",
        "categorical_features = ['job', 'marital', 'education', 'housing', 'loan', 'contact', 'campaign', 'poutcome', 'deposit']\n",
        "\n",
        "# numeric_features = ['balance', 'duration', 'age']\n",
        "# categorical_features = ['marital', 'education']\n",
        "target_label = 'default'\n",
        "\n",
        "\n",
        "df = dfRawFile.select(numeric_features + categorical_features + [target_label])\n",
        "display(df)\n",
        "print(df.take(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "27HGsZ6ArOnW"
      },
      "source": [
        "### Explore numeric features, to see if there is any correlation between values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RMFO0oVOrOnY",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "display(pyh.describe_numeric_features(df, numeric_features))\n",
        "pyh.scatter_matrix(df, numeric_features)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewlJyn9bO616",
        "colab_type": "text"
      },
      "source": [
        "### Use the helper function to reshape it for ML training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CtWabts7rOnc",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "# import imp\n",
        "# imp.reload(pyh)\n",
        "\n",
        "dfML = pyh.MakeMLDataFrame(df, categorical_features, numeric_features, target_label = 'default', target_is_categorical=True)\n",
        "display(dfML)\n",
        "dfML.printSchema()\n",
        "labelCnt = dfML.groupBy('label').count()\n",
        "display(labelCnt)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xw_RBw9xrOnf",
        "colab": {}
      },
      "source": [
        "labelCnt.toPandas().plot(kind = 'bar')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "367IzizFO62G",
        "colab_type": "text"
      },
      "source": [
        "### Save the Vectorized file in case we want to use it again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4AevDiyFrOnp",
        "colab": {}
      },
      "source": [
        "# dfML.write.format('parquet').mode('overwrite').save('testsave')\n",
        "# dfML0 = spark.read.format('parquet').load('testsave')\n",
        "# dfML0.printSchema()\n",
        "# display(dfML0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnEQTEYZO62N",
        "colab_type": "text"
      },
      "source": [
        "### Split it into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FJ5WvSOErOnt",
        "colab": {}
      },
      "source": [
        "#dfML = dfML0\n",
        "train, test = dfML.randomSplit([.7,.3], seed = 100)\n",
        "print (f'Training set row count {train.count()}')\n",
        "print (f'Testing set row count {test.count()}')\n",
        "display(train.groupBy('label').count())\n",
        "display(test.groupBy('label').count())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSpRvGglO62a",
        "colab_type": "text"
      },
      "source": [
        "### Import the Decision Tree classifier and train it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wnOwIT8_rOnw",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
        "dtModel = dt.fit(train)\n",
        "print('DT Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_DT_trainedModel'\n",
        "dtModel.write().overwrite().save(filename1)\n",
        "print('DT Saved')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFrDQ368O62i",
        "colab_type": "text"
      },
      "source": [
        "### Normally there are a lot of steps to predict and test. We have built a helper function to bundle all that up.\n",
        "Take a look at the source code for it to see those indivual steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EByE2E-WrOn0",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "dtPredictions, dtLog = pyh.predict_and_evaluate(dtModel, test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEJCBcNLO62o",
        "colab_type": "text"
      },
      "source": [
        "### Now let's try Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "goWOCubRrOn5",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
        "lrModel = lr.fit(train)\n",
        "print('LR Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_LR_trainedModel'\n",
        "lrModel.write().overwrite().save(filename1)\n",
        "print('LR Saved')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-cP923VO62t",
        "colab_type": "text"
      },
      "source": [
        "### Normally you should be able to load the trained model, but for some reason it's not working correctly on this VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PVPv5t1irOn9",
        "colab": {}
      },
      "source": [
        "#lrModel2 = LogisticRegression.load(filename1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd30mKSkO62z",
        "colab_type": "text"
      },
      "source": [
        "### See the test results as before, but LR has some extra options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RGB_IDUUrOoB",
        "colab": {}
      },
      "source": [
        "lrPredictions, lrLog = pyh.predict_and_evaluate(lrModel, test, showModel = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S75ZIHrO626",
        "colab_type": "text"
      },
      "source": [
        "### Let's try different thresholds to see if we can tweak the false positive/negative balance or improve the overall accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYwEGT7gO628",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr2 = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10, threshold = .1).fit(train)\n",
        "\n",
        "lr2Predictions, lr2Log = pyh.predict_and_evaluate(lr2, test, showModel = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUwIsvyZO63A",
        "colab_type": "text"
      },
      "source": [
        "### After a while it's the same thing over and over, but try out as many models as possible to see which works best.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XoN-fiT2rOoE",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
        "rfModel = rf.fit(train)\n",
        "print('RF Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_RF_trainedModel'\n",
        "rfModel.write().overwrite().save(filename1)\n",
        "print('RF Saved')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aF0GSzKXrOoK",
        "colab": {}
      },
      "source": [
        "rfPredictions, rfLog = pyh.predict_and_evaluate(rfModel, test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UatPEE0HO63K",
        "colab_type": "text"
      },
      "source": [
        "### Try Gradient Boost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90o6tiojrOoO",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "gbt = GBTClassifier(maxIter=10)\n",
        "gbtModel = gbt.fit(train)\n",
        "print ('GBT Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_GBT_trainedModel'\n",
        "rfModel.write().overwrite().save(filename1)\n",
        "print ('GBT Saved')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wuna45UTrOoR",
        "colab": {}
      },
      "source": [
        "gbtPredictions, gbtLog = pyh.predict_and_evaluate(gbtModel, test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_MQBJ1AO63g",
        "colab_type": "text"
      },
      "source": [
        "### Try Neural Networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6QPLoCu1rOoV",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# specify layers for the neural network:\n",
        "# input layer of size 13 (features), two intermediate of size 5 and 4\n",
        "# and output of size 2 (classes)\n",
        "layers = [13, 5, 4, 2]\n",
        "\n",
        "nn = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
        "nnModel = nn.fit(train)\n",
        "print ('NN Trained')\n",
        "\n",
        "filename1 = filename.replace('.','_') + '_NN_trainedModel'\n",
        "nnModel.write().overwrite().save(filename1)\n",
        "print ('NN Saved')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "blt7nlLJrOoe",
        "colab": {}
      },
      "source": [
        "nnPredictions = nnModel.transform(test)\n",
        "print(type(nnPredictions))\n",
        "print(nnPredictions.take(1))\n",
        "nnPredictions.printSchema()\n",
        "print (nnPredictions.count())\n",
        "\n",
        "#nnPredictions, nnLog = pyh.predict_and_evaluate(nnModel, test)\n",
        "##nnPredictions.take(1)\n",
        "# predictionAndLabels = nnPredictions.select(\"prediction\", \"label\")\n",
        "# #display(predictionAndLabels)\n",
        "# print(predictionAndLabels.collect())\n",
        "# evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "# print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EiZnj3adrOot",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}